{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39b8c491-2204-4840-ac12-0cd2cfe16cbc",
   "metadata": {},
   "source": [
    "- references\n",
    "    - https://huggingface.co/docs/peft/developer_guides/model_merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd8489aa-a8df-43d3-bf0b-a98249515381",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "os.environ['http_proxy'] = 'http://127.0.0.1:7890'\n",
    "os.environ['https_proxy'] = 'http://127.0.0.1:7890'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abe2b24e-7458-41b4-8fde-6a86f166ac9e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install --upgrade peft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b7a8372-6369-4cdc-a3c8-70f46bc87e68",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-03-31 11:24:19,352] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    }
   ],
   "source": [
    "from peft import PeftConfig, PeftModel\n",
    "from peft import PeftModel, PeftConfig\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90836ddc-bd98-4266-b2c3-ae18e31936ea",
   "metadata": {},
   "source": [
    "## lora models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d074236-2821-43b6-a007-c5e932c93bc4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "peft_model_id = \"smangrul/tinyllama_lora_norobots\"\n",
    "device = \"cuda\"\n",
    "config = PeftConfig.from_pretrained(peft_model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f733eba-f08a-497c-a951-54047c433167",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LoraConfig(peft_type=<PeftType.LORA: 'LORA'>, auto_mapping=None, base_model_name_or_path='TinyLlama/TinyLlama-1.1B-intermediate-step-1431k-3T', revision=None, task_type='CAUSAL_LM', inference_mode=True, r=8, target_modules={'down_proj', 'q_proj', 'embed_tokens', 'gate_proj', 'o_proj', 'lm_head', 'k_proj', 'up_proj', 'v_proj'}, lora_alpha=16, lora_dropout=0.1, fan_in_fan_out=False, bias='none', use_rslora=False, modules_to_save=None, init_lora_weights=True, layers_to_transform=None, layers_pattern=None, rank_pattern={}, alpha_pattern={}, megatron_config=None, megatron_core='megatron.core', loftq_config={}, use_dora=False, layer_replication=None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76c4e19e-eec4-4f02-9e68-f3ddbb4d1d8e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(config.base_model_name_or_path, load_in_4bit=True, device_map=\"auto\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(peft_model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "823abef7-39ea-4bf6-a5d8-6b0bf65aeb53",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32005"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17873fe9-3a6e-4506-96d1-ffa0e46b341f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57a0f083-5b22-4ef1-b18e-73d67426a62b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(32005, 2048)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "86458827-d43a-4555-9f10-ed99dc984ca7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'<pad>',\n",
       " '<|im_end|>',\n",
       " '<|im_start|>assistant',\n",
       " '<|im_start|>system',\n",
       " '<|im_start|>user'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AutoTokenizer.from_pretrained(\"smangrul/tinyllama_lora_norobots\").vocab.keys() - AutoTokenizer.from_pretrained(\"TinyLlama/TinyLlama-1.1B-intermediate-step-1431k-3T\").vocab.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88625893-a6e8-40d0-85c5-cfacf9dd85ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = PeftModel.from_pretrained(model, peft_model_id, adapter_name=\"norobots\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b083d389-46a1-461d-85c1-5a22f8a319f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = model.load_adapter(\"smangrul/tinyllama_lora_sql\", adapter_name=\"sql\")\n",
    "_ = model.load_adapter(\"smangrul/tinyllama_lora_adcopy\", adapter_name=\"adcopy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5576b5b1-9a46-4923-8ec8-9f350a17c119",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['norobots', 'sql', 'adcopy'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.peft_config.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4360e2-675b-417a-bdde-966b1bef0a9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "79963fce-44cf-488a-9b3a-81d2effcce04",
   "metadata": {},
   "source": [
    "## merge 3 adapters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b68847-b8f4-4222-a46e-db1cce3a9293",
   "metadata": {},
   "source": [
    "- combination_type\n",
    "    - [`svd`, `linear`, `cat`, `ties`, `ties_svd`, `dare_ties`, `dare_linear`, `dare_ties_svd`, `dare_linear_svd`, `magnitude_prune`, `magnitude_prune_svd`]\n",
    "    - `combination_type = \"linear\" if len(adapters) == 1 else combination_type`\n",
    "    - 两种主要的类型\n",
    "        - TIES：TrIm, Elect, and Merge (TIES) is a three-step method for merging models. F\n",
    "        - DARE：Drop And REscale is a method that can be used to prepare for other model merging methods like TIES.\n",
    "- target\n",
    "    - lora_A/lora_B\n",
    "    - lora_embedding_A/lora_embedding_B "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d8c0df65-e87f-4318-8e9d-20ea529264f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "adapters = [\"norobots\", \"adcopy\", \"sql\"]\n",
    "weights = [2.0, 0.3, 0.7]\n",
    "adapter_name = \"merge\"\n",
    "density = 0.2\n",
    "# combination_type = \"ties\"\n",
    "combination_type = \"svd\"\n",
    "if adapter_name in model.peft_config:\n",
    "    model.delete_adapter(adapter_name)\n",
    "model.add_weighted_adapter(adapters, weights, adapter_name, combination_type=combination_type, density=density)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c1c4461c-679b-4a81-a17c-9861a7b88220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "norobots {'down_proj', 'q_proj', 'embed_tokens', 'gate_proj', 'o_proj', 'lm_head', 'k_proj', 'up_proj', 'v_proj'}\n",
      "adcopy {'down_proj', 'gate_proj', 'embed_tokens', 'q_proj', 'o_proj', 'lm_head', 'k_proj', 'up_proj', 'v_proj'}\n",
      "sql {'down_proj', 'q_proj', 'gate_proj', 'o_proj', 'k_proj', 'up_proj', 'v_proj'}\n"
     ]
    }
   ],
   "source": [
    "for adapter in adapters:\n",
    "    print(adapter, model.peft_config[adapter].target_modules)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
