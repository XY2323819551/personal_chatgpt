{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39b8c491-2204-4840-ac12-0cd2cfe16cbc",
   "metadata": {},
   "source": [
    "- references\n",
    "    - https://huggingface.co/blog/peft_merging\n",
    "    - https://huggingface.co/docs/peft/developer_guides/model_merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd8489aa-a8df-43d3-bf0b-a98249515381",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "os.environ['http_proxy'] = 'http://127.0.0.1:7890'\n",
    "os.environ['https_proxy'] = 'http://127.0.0.1:7890'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abe2b24e-7458-41b4-8fde-6a86f166ac9e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install --upgrade peft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b7a8372-6369-4cdc-a3c8-70f46bc87e68",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-04-03 22:26:01,585] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    }
   ],
   "source": [
    "from peft import PeftConfig, PeftModel\n",
    "from peft import PeftModel, PeftConfig\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed524676-de83-4c35-b46f-68fc16598d07",
   "metadata": {},
   "source": [
    "## basics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25b111c-71ea-4e37-a6f2-f6b9ed3fe354",
   "metadata": {},
   "source": [
    "- not only on LLMs, but diffusion models\n",
    "- LoraConfig\n",
    "    - target_modules: The names of the modules to apply the adapter to. \n",
    "    - r: Lora attention dimension (the \"rank\").\n",
    "    - lora_alpha: The alpha parameter for Lora scaling.\n",
    "    - fan_in_fan_out: boolean, 是否先入参再出参（维度、shape 对齐）\n",
    "        ```\n",
    "        # torch.nn.Linear, fan_in_fan_out: False\n",
    "        # y = xA^T + b\n",
    "        self.weight = Parameter(torch.empty((out_features, in_features), **factory_kwargs))\n",
    "        ```\n",
    "    - scaling\n",
    "        ```\n",
    "        # lora.layer\n",
    "        if use_rslora:\n",
    "            self.scaling[adapter_name] = lora_alpha / math.sqrt(r)\n",
    "        else:\n",
    "            self.scaling[adapter_name] = lora_alpha / r\n",
    "        ```\n",
    "\n",
    "- W, lora_a, lora_b\n",
    "    - $\\Delta W = $  lora_b @ lora_a\n",
    "    - $(W+\\Delta W)x=Wx+(lora\\_b @ lora\\_a)x$\n",
    "- combination types\n",
    "    - ties: https://arxiv.org/pdf/2306.01708.pdf\n",
    "    - svd\n",
    "        - $\\Delta_{merged}=weight_1*scaling_1*lora\\_{b1}*lora\\_{a1} + weight_2*scaling_2*lora\\_{b2}*lora\\_{a2}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90836ddc-bd98-4266-b2c3-ae18e31936ea",
   "metadata": {},
   "source": [
    "## lora models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d074236-2821-43b6-a007-c5e932c93bc4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "peft_model_id = \"smangrul/tinyllama_lora_norobots\"\n",
    "device = \"cuda\"\n",
    "config = PeftConfig.from_pretrained(peft_model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f733eba-f08a-497c-a951-54047c433167",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LoraConfig(peft_type=<PeftType.LORA: 'LORA'>, auto_mapping=None, base_model_name_or_path='TinyLlama/TinyLlama-1.1B-intermediate-step-1431k-3T', revision=None, task_type='CAUSAL_LM', inference_mode=True, r=8, target_modules={'k_proj', 'down_proj', 'embed_tokens', 'q_proj', 'lm_head', 'o_proj', 'up_proj', 'v_proj', 'gate_proj'}, lora_alpha=16, lora_dropout=0.1, fan_in_fan_out=False, bias='none', use_rslora=False, modules_to_save=None, init_lora_weights=True, layers_to_transform=None, layers_pattern=None, rank_pattern={}, alpha_pattern={}, megatron_config=None, megatron_core='megatron.core', loftq_config={}, use_dora=False, layer_replication=None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76c4e19e-eec4-4f02-9e68-f3ddbb4d1d8e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(config.base_model_name_or_path, load_in_4bit=True, device_map=\"auto\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(peft_model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "823abef7-39ea-4bf6-a5d8-6b0bf65aeb53",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32005"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17873fe9-3a6e-4506-96d1-ffa0e46b341f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57a0f083-5b22-4ef1-b18e-73d67426a62b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(32005, 2048)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "86458827-d43a-4555-9f10-ed99dc984ca7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'<pad>',\n",
       " '<|im_end|>',\n",
       " '<|im_start|>assistant',\n",
       " '<|im_start|>system',\n",
       " '<|im_start|>user'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AutoTokenizer.from_pretrained(\"smangrul/tinyllama_lora_norobots\").vocab.keys() - AutoTokenizer.from_pretrained(\"TinyLlama/TinyLlama-1.1B-intermediate-step-1431k-3T\").vocab.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88625893-a6e8-40d0-85c5-cfacf9dd85ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = PeftModel.from_pretrained(model, peft_model_id, adapter_name=\"norobots\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b083d389-46a1-461d-85c1-5a22f8a319f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = model.load_adapter(\"smangrul/tinyllama_lora_sql\", adapter_name=\"sql\")\n",
    "_ = model.load_adapter(\"smangrul/tinyllama_lora_adcopy\", adapter_name=\"adcopy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2d46633a-ab50-404a-bf66-d57d471cedc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'norobots': LoraConfig(peft_type=<PeftType.LORA: 'LORA'>, auto_mapping=None, base_model_name_or_path='TinyLlama/TinyLlama-1.1B-intermediate-step-1431k-3T', revision=None, task_type='CAUSAL_LM', inference_mode=True, r=8, target_modules={'k_proj', 'down_proj', 'embed_tokens', 'q_proj', 'lm_head', 'o_proj', 'up_proj', 'v_proj', 'gate_proj'}, lora_alpha=16, lora_dropout=0.1, fan_in_fan_out=False, bias='none', use_rslora=False, modules_to_save=None, init_lora_weights=True, layers_to_transform=None, layers_pattern=None, rank_pattern={}, alpha_pattern={}, megatron_config=None, megatron_core='megatron.core', loftq_config={}, use_dora=False, layer_replication=None),\n",
       " 'sql': LoraConfig(peft_type=<PeftType.LORA: 'LORA'>, auto_mapping=None, base_model_name_or_path='TinyLlama/TinyLlama-1.1B-intermediate-step-1431k-3T', revision=None, task_type='CAUSAL_LM', inference_mode=True, r=8, target_modules={'k_proj', 'down_proj', 'q_proj', 'o_proj', 'up_proj', 'v_proj', 'gate_proj'}, lora_alpha=16, lora_dropout=0.1, fan_in_fan_out=False, bias='none', use_rslora=False, modules_to_save=None, init_lora_weights=True, layers_to_transform=None, layers_pattern=None, rank_pattern={}, alpha_pattern={}, megatron_config=None, megatron_core='megatron.core', loftq_config={}, use_dora=False, layer_replication=None),\n",
       " 'adcopy': LoraConfig(peft_type=<PeftType.LORA: 'LORA'>, auto_mapping=None, base_model_name_or_path='TinyLlama/TinyLlama-1.1B-intermediate-step-1431k-3T', revision=None, task_type='CAUSAL_LM', inference_mode=True, r=8, target_modules={'k_proj', 'down_proj', 'embed_tokens', 'q_proj', 'lm_head', 'up_proj', 'o_proj', 'v_proj', 'gate_proj'}, lora_alpha=16, lora_dropout=0.1, fan_in_fan_out=False, bias='none', use_rslora=False, modules_to_save=None, init_lora_weights=True, layers_to_transform=None, layers_pattern=None, rank_pattern={}, alpha_pattern={}, megatron_config=None, megatron_core='megatron.core', loftq_config={}, use_dora=False, layer_replication=None),\n",
       " 'merge': LoraConfig(peft_type=<PeftType.LORA: 'LORA'>, auto_mapping=None, base_model_name_or_path='TinyLlama/TinyLlama-1.1B-intermediate-step-1431k-3T', revision=None, task_type='CAUSAL_LM', inference_mode=True, r=8, target_modules={'k_proj', 'down_proj', 'embed_tokens', 'q_proj', 'lm_head', 'o_proj', 'up_proj', 'v_proj', 'gate_proj'}, lora_alpha=8, lora_dropout=0.1, fan_in_fan_out=False, bias='none', use_rslora=False, modules_to_save=None, init_lora_weights=True, layers_to_transform=None, layers_pattern=None, rank_pattern={}, alpha_pattern={}, megatron_config=None, megatron_core='megatron.core', loftq_config={}, use_dora=False, layer_replication=None)}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.peft_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5576b5b1-9a46-4923-8ec8-9f350a17c119",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['norobots', 'sql', 'adcopy'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.peft_config.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2b5ce07a-3c53-45c8-9286-1c9248aef56e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "norobots 8 16 2.0 False\n",
      "sql 8 16 2.0 False\n",
      "adcopy 8 16 2.0 False\n",
      "merge 8 8 1.0 False\n"
     ]
    }
   ],
   "source": [
    "for k, v in model.peft_config.items():\n",
    "    print(k, v.r, v.lora_alpha, v.lora_alpha/v.r, v.fan_in_fan_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dc4360e2-675b-417a-bdde-966b1bef0a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79963fce-44cf-488a-9b3a-81d2effcce04",
   "metadata": {},
   "source": [
    "## merge 3 adapters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b68847-b8f4-4222-a46e-db1cce3a9293",
   "metadata": {},
   "source": [
    "- combination_type\n",
    "    - [`svd`, `linear`, `cat`, `ties`, `ties_svd`, `dare_ties`, `dare_linear`, `dare_ties_svd`, `dare_linear_svd`, `magnitude_prune`, `magnitude_prune_svd`]\n",
    "    - `combination_type = \"linear\" if len(adapters) == 1 else combination_type`\n",
    "    - 两种主要的类型\n",
    "        - TIES：TrIm, Elect, and Merge (TIES) is a three-step method for merging models. F\n",
    "        - DARE：Drop And REscale is a method that can be used to prepare for other model merging methods like TIES.\n",
    "    - 实现上\n",
    "        -  `cat`\n",
    "        -  `[svd, ties_svd, dare_linear_svd, dare_ties_svd, magnitude_prune_svd]`\n",
    "        -  `[linear, ties, dare_linear, dare_ties, magnitude_prune]`\n",
    "- target\n",
    "    - lora_A/lora_B\n",
    "    - lora_embedding_A/lora_embedding_B "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d8c0df65-e87f-4318-8e9d-20ea529264f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "adapters = [\"norobots\", \"adcopy\", \"sql\"]\n",
    "weights = [2.0, 0.3, 0.7]\n",
    "adapter_name = \"merge\"\n",
    "density = 0.2\n",
    "# combination_type = \"ties\"\n",
    "combination_type = \"svd\"\n",
    "if adapter_name in model.peft_config:\n",
    "    model.delete_adapter(adapter_name)\n",
    "model.add_weighted_adapter(adapters, weights, adapter_name, combination_type=combination_type, density=density)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a17bac1b-3bf5-4597-8ac0-f3bab23c4f22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "norobots {'k_proj', 'down_proj', 'embed_tokens', 'q_proj', 'lm_head', 'o_proj', 'up_proj', 'v_proj', 'gate_proj'}\n",
      "adcopy {'k_proj', 'down_proj', 'embed_tokens', 'q_proj', 'lm_head', 'up_proj', 'o_proj', 'v_proj', 'gate_proj'}\n",
      "sql {'k_proj', 'down_proj', 'q_proj', 'o_proj', 'up_proj', 'v_proj', 'gate_proj'}\n"
     ]
    }
   ],
   "source": [
    "for adapter in adapters:\n",
    "    print(adapter, model.peft_config[adapter].target_modules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "73962bbc-f61f-4230-9108-4d851dd9c5f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): LlamaForCausalLM(\n",
       "      (model): LlamaModel(\n",
       "        (embed_tokens): lora.Embedding(\n",
       "          (base_layer): Embedding(32005, 2048)\n",
       "          (lora_dropout): ModuleDict(\n",
       "            (norobots): Dropout(p=0.1, inplace=False)\n",
       "            (adcopy): Dropout(p=0.1, inplace=False)\n",
       "            (merge): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (lora_A): ModuleDict()\n",
       "          (lora_B): ModuleDict()\n",
       "          (lora_embedding_A): ParameterDict(\n",
       "              (norobots): Parameter containing: [torch.cuda.HalfTensor of size 8x32005 (GPU 0)]\n",
       "              (adcopy): Parameter containing: [torch.cuda.HalfTensor of size 8x32005 (GPU 0)]\n",
       "              (merge): Parameter containing: [torch.cuda.FloatTensor of size 8x32005 (GPU 0)]\n",
       "          )\n",
       "          (lora_embedding_B): ParameterDict(\n",
       "              (norobots): Parameter containing: [torch.cuda.HalfTensor of size 2048x8 (GPU 0)]\n",
       "              (adcopy): Parameter containing: [torch.cuda.HalfTensor of size 2048x8 (GPU 0)]\n",
       "              (merge): Parameter containing: [torch.cuda.FloatTensor of size 2048x8 (GPU 0)]\n",
       "          )\n",
       "        )\n",
       "        (layers): ModuleList(\n",
       "          (0-21): 22 x LlamaDecoderLayer(\n",
       "            (self_attn): LlamaAttention(\n",
       "              (q_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=2048, out_features=2048, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (norobots): Dropout(p=0.1, inplace=False)\n",
       "                  (sql): Dropout(p=0.1, inplace=False)\n",
       "                  (adcopy): Dropout(p=0.1, inplace=False)\n",
       "                  (merge): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (norobots): Linear(in_features=2048, out_features=8, bias=False)\n",
       "                  (sql): Linear(in_features=2048, out_features=8, bias=False)\n",
       "                  (adcopy): Linear(in_features=2048, out_features=8, bias=False)\n",
       "                  (merge): Linear(in_features=2048, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (norobots): Linear(in_features=8, out_features=2048, bias=False)\n",
       "                  (sql): Linear(in_features=8, out_features=2048, bias=False)\n",
       "                  (adcopy): Linear(in_features=8, out_features=2048, bias=False)\n",
       "                  (merge): Linear(in_features=8, out_features=2048, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (k_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=2048, out_features=256, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (norobots): Dropout(p=0.1, inplace=False)\n",
       "                  (sql): Dropout(p=0.1, inplace=False)\n",
       "                  (adcopy): Dropout(p=0.1, inplace=False)\n",
       "                  (merge): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (norobots): Linear(in_features=2048, out_features=8, bias=False)\n",
       "                  (sql): Linear(in_features=2048, out_features=8, bias=False)\n",
       "                  (adcopy): Linear(in_features=2048, out_features=8, bias=False)\n",
       "                  (merge): Linear(in_features=2048, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (norobots): Linear(in_features=8, out_features=256, bias=False)\n",
       "                  (sql): Linear(in_features=8, out_features=256, bias=False)\n",
       "                  (adcopy): Linear(in_features=8, out_features=256, bias=False)\n",
       "                  (merge): Linear(in_features=8, out_features=256, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (v_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=2048, out_features=256, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (norobots): Dropout(p=0.1, inplace=False)\n",
       "                  (sql): Dropout(p=0.1, inplace=False)\n",
       "                  (adcopy): Dropout(p=0.1, inplace=False)\n",
       "                  (merge): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (norobots): Linear(in_features=2048, out_features=8, bias=False)\n",
       "                  (sql): Linear(in_features=2048, out_features=8, bias=False)\n",
       "                  (adcopy): Linear(in_features=2048, out_features=8, bias=False)\n",
       "                  (merge): Linear(in_features=2048, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (norobots): Linear(in_features=8, out_features=256, bias=False)\n",
       "                  (sql): Linear(in_features=8, out_features=256, bias=False)\n",
       "                  (adcopy): Linear(in_features=8, out_features=256, bias=False)\n",
       "                  (merge): Linear(in_features=8, out_features=256, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (o_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=2048, out_features=2048, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (norobots): Dropout(p=0.1, inplace=False)\n",
       "                  (sql): Dropout(p=0.1, inplace=False)\n",
       "                  (adcopy): Dropout(p=0.1, inplace=False)\n",
       "                  (merge): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (norobots): Linear(in_features=2048, out_features=8, bias=False)\n",
       "                  (sql): Linear(in_features=2048, out_features=8, bias=False)\n",
       "                  (adcopy): Linear(in_features=2048, out_features=8, bias=False)\n",
       "                  (merge): Linear(in_features=2048, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (norobots): Linear(in_features=8, out_features=2048, bias=False)\n",
       "                  (sql): Linear(in_features=8, out_features=2048, bias=False)\n",
       "                  (adcopy): Linear(in_features=8, out_features=2048, bias=False)\n",
       "                  (merge): Linear(in_features=8, out_features=2048, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (rotary_emb): LlamaRotaryEmbedding()\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=2048, out_features=5632, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (norobots): Dropout(p=0.1, inplace=False)\n",
       "                  (sql): Dropout(p=0.1, inplace=False)\n",
       "                  (adcopy): Dropout(p=0.1, inplace=False)\n",
       "                  (merge): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (norobots): Linear(in_features=2048, out_features=8, bias=False)\n",
       "                  (sql): Linear(in_features=2048, out_features=8, bias=False)\n",
       "                  (adcopy): Linear(in_features=2048, out_features=8, bias=False)\n",
       "                  (merge): Linear(in_features=2048, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (norobots): Linear(in_features=8, out_features=5632, bias=False)\n",
       "                  (sql): Linear(in_features=8, out_features=5632, bias=False)\n",
       "                  (adcopy): Linear(in_features=8, out_features=5632, bias=False)\n",
       "                  (merge): Linear(in_features=8, out_features=5632, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (up_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=2048, out_features=5632, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (norobots): Dropout(p=0.1, inplace=False)\n",
       "                  (sql): Dropout(p=0.1, inplace=False)\n",
       "                  (adcopy): Dropout(p=0.1, inplace=False)\n",
       "                  (merge): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (norobots): Linear(in_features=2048, out_features=8, bias=False)\n",
       "                  (sql): Linear(in_features=2048, out_features=8, bias=False)\n",
       "                  (adcopy): Linear(in_features=2048, out_features=8, bias=False)\n",
       "                  (merge): Linear(in_features=2048, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (norobots): Linear(in_features=8, out_features=5632, bias=False)\n",
       "                  (sql): Linear(in_features=8, out_features=5632, bias=False)\n",
       "                  (adcopy): Linear(in_features=8, out_features=5632, bias=False)\n",
       "                  (merge): Linear(in_features=8, out_features=5632, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (down_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=5632, out_features=2048, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (norobots): Dropout(p=0.1, inplace=False)\n",
       "                  (sql): Dropout(p=0.1, inplace=False)\n",
       "                  (adcopy): Dropout(p=0.1, inplace=False)\n",
       "                  (merge): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (norobots): Linear(in_features=5632, out_features=8, bias=False)\n",
       "                  (sql): Linear(in_features=5632, out_features=8, bias=False)\n",
       "                  (adcopy): Linear(in_features=5632, out_features=8, bias=False)\n",
       "                  (merge): Linear(in_features=5632, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (norobots): Linear(in_features=8, out_features=2048, bias=False)\n",
       "                  (sql): Linear(in_features=8, out_features=2048, bias=False)\n",
       "                  (adcopy): Linear(in_features=8, out_features=2048, bias=False)\n",
       "                  (merge): Linear(in_features=8, out_features=2048, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm()\n",
       "            (post_attention_layernorm): LlamaRMSNorm()\n",
       "          )\n",
       "        )\n",
       "        (norm): LlamaRMSNorm()\n",
       "      )\n",
       "      (lm_head): lora.Linear(\n",
       "        (base_layer): Linear(in_features=2048, out_features=32005, bias=False)\n",
       "        (lora_dropout): ModuleDict(\n",
       "          (norobots): Dropout(p=0.1, inplace=False)\n",
       "          (adcopy): Dropout(p=0.1, inplace=False)\n",
       "          (merge): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (lora_A): ModuleDict(\n",
       "          (norobots): Linear(in_features=2048, out_features=8, bias=False)\n",
       "          (adcopy): Linear(in_features=2048, out_features=8, bias=False)\n",
       "          (merge): Linear(in_features=2048, out_features=8, bias=False)\n",
       "        )\n",
       "        (lora_B): ModuleDict(\n",
       "          (norobots): Linear(in_features=8, out_features=32005, bias=False)\n",
       "          (adcopy): Linear(in_features=8, out_features=32005, bias=False)\n",
       "          (merge): Linear(in_features=8, out_features=32005, bias=False)\n",
       "        )\n",
       "        (lora_embedding_A): ParameterDict()\n",
       "        (lora_embedding_B): ParameterDict()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8acbf6d8-a350-4cf9-96aa-43689421a43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.base_model.model.model.layers[0].mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a8478ba0-29ca-47ea-a4ad-3e9fb4731392",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'norobots': 2.0, 'adcopy': 2.0, 'merge': 1.0}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model.get_submodule('model.embed_tokens').scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "199e2e17-bd12-4d5a-a172-80028ace8ba8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "peft.tuners.lora.bnb.Linear4bit"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model.model.get_submodule('model.layers.0.self_attn.q_proj'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99bbe71f-e9b0-4443-ba61-107c650434f0",
   "metadata": {},
   "source": [
    "### from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5e7f70c3-7f13-4854-893f-ef639a65352a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lora.Embedding(\n",
       "  (base_layer): Embedding(32005, 2048)\n",
       "  (lora_dropout): ModuleDict(\n",
       "    (norobots): Dropout(p=0.1, inplace=False)\n",
       "    (adcopy): Dropout(p=0.1, inplace=False)\n",
       "    (merge): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lora_A): ModuleDict()\n",
       "  (lora_B): ModuleDict()\n",
       "  (lora_embedding_A): ParameterDict(\n",
       "      (norobots): Parameter containing: [torch.cuda.HalfTensor of size 8x32005 (GPU 0)]\n",
       "      (adcopy): Parameter containing: [torch.cuda.HalfTensor of size 8x32005 (GPU 0)]\n",
       "      (merge): Parameter containing: [torch.cuda.FloatTensor of size 8x32005 (GPU 0)]\n",
       "  )\n",
       "  (lora_embedding_B): ParameterDict(\n",
       "      (norobots): Parameter containing: [torch.cuda.HalfTensor of size 2048x8 (GPU 0)]\n",
       "      (adcopy): Parameter containing: [torch.cuda.HalfTensor of size 2048x8 (GPU 0)]\n",
       "      (merge): Parameter containing: [torch.cuda.FloatTensor of size 2048x8 (GPU 0)]\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.base_model.model.model.embed_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c1c4461c-679b-4a81-a17c-9861a7b88220",
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_a_1 = model.base_model.model.model.embed_tokens.lora_embedding_A['norobots']\n",
    "lora_a_2 = model.base_model.model.model.embed_tokens.lora_embedding_A['adcopy']\n",
    "lora_b_1 = model.base_model.model.model.embed_tokens.lora_embedding_B['norobots']\n",
    "lora_b_2 = model.base_model.model.model.embed_tokens.lora_embedding_B['adcopy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e1c97186-cb80-4eed-8a98-1f8f7c59be0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([8, 32005]),\n",
       " torch.Size([2048, 8]),\n",
       " torch.Size([8, 32005]),\n",
       " torch.Size([2048, 8]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lora_a_1.shape, lora_b_1.shape, lora_a_2.shape, lora_b_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eccc2d7-c2ea-4632-8d85-b57bdfe45bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaling = [2, 2]\n",
    "weights = [2, 0.3] \n",
    "valid_weights = [2*2, 2*0.3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8dd3e6-750c-4f3f-8691-206c27e7e46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transpose(weight, fan_in_fan_out):\n",
    "    if not fan_in_fan_out:\n",
    "        return weight\n",
    "\n",
    "    if isinstance(weight, torch.nn.Parameter):\n",
    "        return torch.nn.Parameter(weight.T)\n",
    "    return weight.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579376cd-c1fa-48b6-9daf-9b0bc0c594e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_lora_1 = transpose(lora_b_1 @ lora_a_1, True) * scaling[0]\n",
    "delta_lora_2 = transpose(lora_b_2 @ lora_a_2, True) * scaling[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936ff6a2-6c28-4a35-a892-f93acf0539f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_lora_1.shape, delta_lora_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6e780f-9785-48f2-a66e-d83b90f0410f",
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_lora = valid_weights[0] * delta_lora_1 + valid_weights[1] * delta_lora_2\n",
    "delta_lora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1d76f3-1b6f-4305-ae70-b3b99081fb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_lora = delta_lora.T\n",
    "U, S, Vh = torch.linalg.svd(delta_lora.float(), full_matrices=True)\n",
    "U = U[:, :8]\n",
    "S = S[:8]\n",
    "U = U @ torch.diag(S)\n",
    "Vh = Vh[:8, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c872f042-7927-4640-b7ab-f529a1ba9784",
   "metadata": {},
   "outputs": [],
   "source": [
    "Vh.shape, U.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47af37e4-c2fb-4370-aac5-532c5064598e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Vh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f45f12-0f99-4ac8-a86a-3da2e843ece4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_a_new = model.base_model.model.model.embed_tokens.lora_embedding_A['merge']\n",
    "lora_b_new = model.base_model.model.model.embed_tokens.lora_embedding_B['merge']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b7900e-6f8e-4276-b061-0e35b8e7053d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_a_new.shape, lora_b_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b422794-ad4e-48b7-aa80-7372778a9bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_a_new"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
