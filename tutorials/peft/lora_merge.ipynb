{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39b8c491-2204-4840-ac12-0cd2cfe16cbc",
   "metadata": {},
   "source": [
    "- references\n",
    "    - https://huggingface.co/blog/peft_merging\n",
    "    - https://huggingface.co/docs/peft/developer_guides/model_merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd8489aa-a8df-43d3-bf0b-a98249515381",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "os.environ['http_proxy'] = 'http://127.0.0.1:7890'\n",
    "os.environ['https_proxy'] = 'http://127.0.0.1:7890'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abe2b24e-7458-41b4-8fde-6a86f166ac9e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install --upgrade peft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b7a8372-6369-4cdc-a3c8-70f46bc87e68",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-03-31 20:18:22,363] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    }
   ],
   "source": [
    "from peft import PeftConfig, PeftModel\n",
    "from peft import PeftModel, PeftConfig\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90836ddc-bd98-4266-b2c3-ae18e31936ea",
   "metadata": {},
   "source": [
    "## lora models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d074236-2821-43b6-a007-c5e932c93bc4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "peft_model_id = \"smangrul/tinyllama_lora_norobots\"\n",
    "device = \"cuda\"\n",
    "config = PeftConfig.from_pretrained(peft_model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f733eba-f08a-497c-a951-54047c433167",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LoraConfig(peft_type=<PeftType.LORA: 'LORA'>, auto_mapping=None, base_model_name_or_path='TinyLlama/TinyLlama-1.1B-intermediate-step-1431k-3T', revision=None, task_type='CAUSAL_LM', inference_mode=True, r=8, target_modules={'down_proj', 'v_proj', 'embed_tokens', 'q_proj', 'k_proj', 'gate_proj', 'lm_head', 'o_proj', 'up_proj'}, lora_alpha=16, lora_dropout=0.1, fan_in_fan_out=False, bias='none', use_rslora=False, modules_to_save=None, init_lora_weights=True, layers_to_transform=None, layers_pattern=None, rank_pattern={}, alpha_pattern={}, megatron_config=None, megatron_core='megatron.core', loftq_config={}, use_dora=False, layer_replication=None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76c4e19e-eec4-4f02-9e68-f3ddbb4d1d8e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(config.base_model_name_or_path, load_in_4bit=True, device_map=\"auto\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(peft_model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "823abef7-39ea-4bf6-a5d8-6b0bf65aeb53",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32005"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17873fe9-3a6e-4506-96d1-ffa0e46b341f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57a0f083-5b22-4ef1-b18e-73d67426a62b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(32005, 2048)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "86458827-d43a-4555-9f10-ed99dc984ca7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'<pad>',\n",
       " '<|im_end|>',\n",
       " '<|im_start|>assistant',\n",
       " '<|im_start|>system',\n",
       " '<|im_start|>user'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AutoTokenizer.from_pretrained(\"smangrul/tinyllama_lora_norobots\").vocab.keys() - AutoTokenizer.from_pretrained(\"TinyLlama/TinyLlama-1.1B-intermediate-step-1431k-3T\").vocab.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88625893-a6e8-40d0-85c5-cfacf9dd85ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = PeftModel.from_pretrained(model, peft_model_id, adapter_name=\"norobots\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b083d389-46a1-461d-85c1-5a22f8a319f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = model.load_adapter(\"smangrul/tinyllama_lora_sql\", adapter_name=\"sql\")\n",
    "_ = model.load_adapter(\"smangrul/tinyllama_lora_adcopy\", adapter_name=\"adcopy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5576b5b1-9a46-4923-8ec8-9f350a17c119",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['norobots', 'sql', 'adcopy'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.peft_config.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fa76f1f2-7260-467b-9746-bd414760add8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "norobots {'down_proj', 'v_proj', 'embed_tokens', 'q_proj', 'k_proj', 'gate_proj', 'lm_head', 'o_proj', 'up_proj'}\n",
      "adcopy {'v_proj', 'k_proj', 'embed_tokens', 'q_proj', 'down_proj', 'gate_proj', 'lm_head', 'o_proj', 'up_proj'}\n",
      "sql {'v_proj', 'down_proj', 'q_proj', 'k_proj', 'gate_proj', 'o_proj', 'up_proj'}\n"
     ]
    }
   ],
   "source": [
    "for adapter in adapters:\n",
    "    print(adapter, model.peft_config[adapter].target_modules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dc4360e2-675b-417a-bdde-966b1bef0a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79963fce-44cf-488a-9b3a-81d2effcce04",
   "metadata": {},
   "source": [
    "## merge 3 adapters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b68847-b8f4-4222-a46e-db1cce3a9293",
   "metadata": {},
   "source": [
    "- combination_type\n",
    "    - [`svd`, `linear`, `cat`, `ties`, `ties_svd`, `dare_ties`, `dare_linear`, `dare_ties_svd`, `dare_linear_svd`, `magnitude_prune`, `magnitude_prune_svd`]\n",
    "    - `combination_type = \"linear\" if len(adapters) == 1 else combination_type`\n",
    "    - 两种主要的类型\n",
    "        - TIES：TrIm, Elect, and Merge (TIES) is a three-step method for merging models. F\n",
    "        - DARE：Drop And REscale is a method that can be used to prepare for other model merging methods like TIES.\n",
    "    - 实现上\n",
    "        -  `cat`\n",
    "        -  `[svd, ties_svd, dare_linear_svd, dare_ties_svd, magnitude_prune_svd]`\n",
    "        -  `[linear, ties, dare_linear, dare_ties, magnitude_prune]`\n",
    "- target\n",
    "    - lora_A/lora_B\n",
    "    - lora_embedding_A/lora_embedding_B "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d8c0df65-e87f-4318-8e9d-20ea529264f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "adapters = [\"norobots\", \"adcopy\", \"sql\"]\n",
    "weights = [2.0, 0.3, 0.7]\n",
    "adapter_name = \"merge\"\n",
    "density = 0.2\n",
    "# combination_type = \"ties\"\n",
    "combination_type = \"svd\"\n",
    "if adapter_name in model.peft_config:\n",
    "    model.delete_adapter(adapter_name)\n",
    "model.add_weighted_adapter(adapters, weights, adapter_name, combination_type=combination_type, density=density)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "73962bbc-f61f-4230-9108-4d851dd9c5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99bbe71f-e9b0-4443-ba61-107c650434f0",
   "metadata": {},
   "source": [
    "### from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5e7f70c3-7f13-4854-893f-ef639a65352a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ParameterDict(\n",
       "    (norobots): Parameter containing: [torch.cuda.HalfTensor of size 8x32005 (GPU 0)]\n",
       "    (adcopy): Parameter containing: [torch.cuda.HalfTensor of size 8x32005 (GPU 0)]\n",
       "    (merge): Parameter containing: [torch.cuda.FloatTensor of size 8x32005 (GPU 0)]\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.base_model.model.model.embed_tokens.lora_embedding_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c1c4461c-679b-4a81-a17c-9861a7b88220",
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_a_1 = model.base_model.model.model.embed_tokens.lora_embedding_A['norobots']\n",
    "lora_a_2 = model.base_model.model.model.embed_tokens.lora_embedding_A['adcopy']\n",
    "lora_b_1 = model.base_model.model.model.embed_tokens.lora_embedding_B['norobots']\n",
    "lora_b_2 = model.base_model.model.model.embed_tokens.lora_embedding_B['adcopy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e1c97186-cb80-4eed-8a98-1f8f7c59be0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([8, 32005]),\n",
       " torch.Size([2048, 8]),\n",
       " torch.Size([8, 32005]),\n",
       " torch.Size([2048, 8]))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lora_a_1.shape, lora_b_1.shape, lora_a_2.shape, lora_b_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6eccc2d7-c2ea-4632-8d85-b57bdfe45bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaling = [2, 2]\n",
    "weights = [2, 0.3] \n",
    "valid_weights = [2*2, 2*0.3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0a8dd3e6-750c-4f3f-8691-206c27e7e46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transpose(weight, fan_in_fan_out):\n",
    "    if not fan_in_fan_out:\n",
    "        return weight\n",
    "\n",
    "    if isinstance(weight, torch.nn.Parameter):\n",
    "        return torch.nn.Parameter(weight.T)\n",
    "    return weight.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "579376cd-c1fa-48b6-9daf-9b0bc0c594e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_lora_1 = transpose(lora_b_1 @ lora_a_1, True) * scaling[0]\n",
    "delta_lora_2 = transpose(lora_b_2 @ lora_a_2, True) * scaling[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "936ff6a2-6c28-4a35-a892-f93acf0539f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32005, 2048]), torch.Size([32005, 2048]))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta_lora_1.shape, delta_lora_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7e6e780f-9785-48f2-a66e-d83b90f0410f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0147,  0.0087,  0.0105,  ...,  0.0161,  0.0129, -0.0181],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        ...,\n",
       "        [-0.0150,  0.0119, -0.0298,  ..., -0.0230, -0.0261, -0.0239],\n",
       "        [-0.0233, -0.0274, -0.0006,  ..., -0.0169, -0.0194,  0.0371],\n",
       "        [ 0.0084,  0.0575, -0.0138,  ..., -0.0258,  0.0178,  0.0437]],\n",
       "       device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta_lora = valid_weights[0] * delta_lora_1 + valid_weights[1] * delta_lora_2\n",
    "delta_lora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8b1d76f3-1b6f-4305-ae70-b3b99081fb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_lora = delta_lora.T\n",
    "U, S, Vh = torch.linalg.svd(delta_lora.float(), full_matrices=True)\n",
    "U = U[:, :8]\n",
    "S = S[:8]\n",
    "U = U @ torch.diag(S)\n",
    "Vh = Vh[:8, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c872f042-7927-4640-b7ab-f529a1ba9784",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([8, 32005]), torch.Size([2048, 8]))"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Vh.shape, U.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "47af37e4-c2fb-4370-aac5-532c5064598e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-5.9250e-08,  3.6710e-03,  5.8551e-09,  ..., -5.5535e-03,\n",
       "         -1.1281e-02, -5.8577e-03],\n",
       "        [-5.3737e-08,  7.6944e-03, -9.9491e-09,  ..., -1.8266e-02,\n",
       "         -2.5229e-02,  5.2019e-03],\n",
       "        [-2.8191e-08, -3.8739e-03, -2.3445e-09,  ..., -2.6179e-03,\n",
       "         -1.5592e-03,  2.8683e-02],\n",
       "        ...,\n",
       "        [ 1.6487e-08, -3.0573e-03, -1.4432e-10,  ...,  9.0157e-03,\n",
       "         -2.2049e-02,  4.6260e-03],\n",
       "        [-2.2342e-08,  1.2938e-02, -5.7639e-09,  ...,  1.6897e-02,\n",
       "          8.5601e-03, -1.1252e-02],\n",
       "        [-1.0293e-08, -4.6255e-03, -2.4660e-08,  ..., -1.4191e-02,\n",
       "          1.2497e-02,  6.5705e-03]], device='cuda:0', grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Vh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c8f45f12-0f99-4ac8-a86a-3da2e843ece4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_a_new = model.base_model.model.model.embed_tokens.lora_embedding_A['merge']\n",
    "lora_b_new = model.base_model.model.model.embed_tokens.lora_embedding_B['merge']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "48b7900e-6f8e-4276-b061-0e35b8e7053d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([8, 32005]), torch.Size([2048, 8]))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lora_a_new.shape, lora_b_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0b422794-ad4e-48b7-aa80-7372778a9bb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 6.6927e-08,  3.6697e-03, -4.0709e-08,  ..., -5.5574e-03,\n",
       "         -1.1279e-02, -5.8365e-03],\n",
       "        [ 5.2394e-08,  7.7513e-03,  3.8410e-08,  ..., -1.8233e-02,\n",
       "         -2.5212e-02,  4.8264e-03],\n",
       "        [-3.8023e-08,  3.7841e-03,  8.6544e-09,  ...,  2.8255e-03,\n",
       "          1.8587e-03, -2.8766e-02],\n",
       "        ...,\n",
       "        [-2.4451e-09, -3.0670e-03, -6.7911e-09,  ...,  8.9840e-03,\n",
       "         -2.2061e-02,  4.7337e-03],\n",
       "        [-3.0357e-08, -1.2936e-02, -3.8171e-09,  ..., -1.6890e-02,\n",
       "         -8.5719e-03,  1.1253e-02],\n",
       "        [ 1.4960e-08, -4.6251e-03,  7.7989e-08,  ..., -1.4207e-02,\n",
       "          1.2501e-02,  6.5824e-03]], device='cuda:0')"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lora_a_new"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
