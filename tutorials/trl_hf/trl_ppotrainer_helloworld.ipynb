{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5fe16cf4-1248-44a9-8d7f-1a3100c90d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['http_proxy'] = 'http://127.0.0.1:7890'\n",
    "os.environ['https_proxy'] = 'http://127.0.0.1:7890'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71d20e65-03d9-4239-98c3-34eb7e71cb83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/whaow/anaconda3/lib/python3.10/site-packages/diffusers/utils/outputs.py:63: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:\n",
      "    PyTorch 2.0.1 with CUDA 1108 (you have 2.2.2+cu121)\n",
      "    Python  3.10.13 (you have 3.10.13)\n",
      "  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)\n",
      "  Memory-efficient attention, SwiGLU, sparse and more won't be available.\n",
      "  Set XFORMERS_MORE_DETAILS=1 for more details\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-05-21 23:16:34,051] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import GPT2Tokenizer\n",
    "\n",
    "from trl import AutoModelForCausalLMWithValueHead, PPOConfig, PPOTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7637d319-f864-41f5-9bb0-643b92d460e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!export NCCL_P2P_DISABLE=\"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041ad753-b11e-48a0-99ce-9273ced105b1",
   "metadata": {},
   "source": [
    "## model vs. model_ref"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ab4895-7437-4e85-89b4-2f717fd790da",
   "metadata": {},
   "source": [
    "- `AutoModelForCausalLMWithValueHead`\n",
    "    - `ValueHead`:  `self.summary = nn.Linear(hidden_size, 1)` (hidden_size => 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6ef8e80-57fd-4640-98e3-b49b9c867529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. load a pretrained model\n",
    "model = AutoModelForCausalLMWithValueHead.from_pretrained(\"gpt2\")\n",
    "model_ref = AutoModelForCausalLMWithValueHead.from_pretrained(\"gpt2\")\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf1d705d-b7bc-4fd5-9e18-33b3c8d32b73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/whaow/anaconda3/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:257: UserWarning: No dataset is provided. Make sure to set config.batch_size to the correct value before training.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 2. initialize trainer\n",
    "ppo_config = {\"mini_batch_size\": 1, \"batch_size\": 1}\n",
    "config = PPOConfig(**ppo_config)\n",
    "ppo_trainer = PPOTrainer(config, model, model_ref, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8977d1b-c9fa-40d4-b36a-5dc2bbc3f5bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1212, 3329,  314, 1816,  284,  262,  220]], device='cuda:0')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. encode a query\n",
    "query_txt = \"This morning I went to the \"\n",
    "query_tensor = tokenizer.encode(query_txt, return_tensors=\"pt\").to(model.pretrained_model.device)\n",
    "query_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f63f0b6-3011-4b3e-ba75-27f228be9a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. generate model response\n",
    "generation_kwargs = {\n",
    "    \"min_length\": -1,\n",
    "    \"top_k\": 0.0,\n",
    "    \"top_p\": 1.0,\n",
    "    \"do_sample\": True,\n",
    "    \"pad_token_id\": tokenizer.eos_token_id,\n",
    "    \"max_new_tokens\": 20,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0338d94d-242d-42b3-8e35-6865aa482360",
   "metadata": {},
   "source": [
    "## `ppo_trainer.generate`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea29ab87-4db0-49ab-9fb8-dbb4a335136c",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_tensor = ppo_trainer.generate(list(query_tensor), return_prompt=False, **generation_kwargs)\n",
    "response_txt = tokenizer.decode(response_tensor[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a67c370a-9303-4df7-b5bb-3ef751098879",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. define a reward for response\n",
    "# (this could be any reward such as human feedback or output from another model)\n",
    "reward = [torch.tensor(1.0, device=model.pretrained_model.device)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926222a3-f8de-4c7c-ae68-9dd6bf75215e",
   "metadata": {},
   "source": [
    "## `ppo_trainer.step`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a3face7-79e7-4474-9651-9f19153066aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/whaow/anaconda3/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1275: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at ../aten/src/ATen/native/ReduceOps.cpp:1760.)\n",
      "  std_scores = data[\"scores\"].std()\n",
      "/home/whaow/anaconda3/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1302: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at ../aten/src/ATen/native/ReduceOps.cpp:1760.)\n",
      "  stats[\"tokens/queries_len_std\"] = torch.std(query_lens).cpu().numpy().item()\n",
      "/home/whaow/anaconda3/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1305: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at ../aten/src/ATen/native/ReduceOps.cpp:1760.)\n",
      "  stats[\"tokens/responses_len_std\"] = torch.std(response_lens).cpu().numpy().item()\n"
     ]
    }
   ],
   "source": [
    "train_stats = ppo_trainer.step([query_tensor[0]], [response_tensor[0]], reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "48ade59b-1c66-49b1-90c9-22e6ad02c148",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['objective/kl', 'objective/kl_dist', 'objective/logprobs', 'objective/ref_logprobs', 'objective/kl_coef', 'objective/entropy', 'ppo/mean_non_score_reward', 'ppo/mean_scores', 'ppo/std_scores', 'tokens/queries_len_mean', 'tokens/queries_len_std', 'tokens/queries_dist', 'tokens/responses_len_mean', 'tokens/responses_len_std', 'tokens/responses_dist', 'ppo/loss/policy', 'ppo/loss/value', 'ppo/loss/total', 'ppo/policy/entropy', 'ppo/policy/approxkl', 'ppo/policy/policykl', 'ppo/policy/clipfrac', 'ppo/policy/advantages', 'ppo/policy/advantages_mean', 'ppo/policy/ratio', 'ppo/returns/mean', 'ppo/returns/var', 'ppo/val/vpred', 'ppo/val/error', 'ppo/val/clipfrac', 'ppo/val/mean', 'ppo/val/var', 'ppo/val/var_explained', 'ppo/learning_rate', 'time/ppo/forward_pass', 'time/ppo/compute_rewards', 'time/ppo/compute_advantages', 'time/ppo/optimize_step', 'time/ppo/calc_stats', 'time/ppo/total'])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_stats.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413d9044-85ac-46bc-ad43-61e0c05792a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
